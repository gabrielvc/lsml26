{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "456b6e7a",
   "metadata": {},
   "source": [
    "# **MNIST-1D**: Observing deep double descent\n",
    "\n",
    "This notebook was originally proposed at [MNIST 1D github repo](https://github.com/greydanus/mnist1d/blob/master/notebooks/deep-double-descent.ipynb) and adapted by Gabriel V. Cardoso.\n",
    "\n",
    "The goal of this notebook is to reproduce the double descent experiment with different networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f6c3dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05b4dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 40)\n",
      "(12000, 40)\n"
     ]
    }
   ],
   "source": [
    "from mnist1d.data import make_dataset, get_dataset_args\n",
    "\n",
    "args = get_dataset_args()\n",
    "args.num_samples = 16_000\n",
    "args.train_split = 0.25\n",
    "\n",
    "data = make_dataset(args)\n",
    "\n",
    "print(data['x'].shape)\n",
    "print(data['x_test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73de6de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 15% noise to training labels\n",
    "\n",
    "import copy\n",
    "data_with_label_noise = copy.deepcopy(data)\n",
    "\n",
    "for i in range(len(data['y'])):\n",
    "    if np.random.random_sample() < 0.15:\n",
    "        data_with_label_noise['y'][i] = np.random.randint(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06fd8ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP architecture with one hidden layer\n",
    "\n",
    "def get_model(n_hidden):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(40, n_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden, n_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72455c0",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "\n",
    "Write a `fit_model` function according to the docstring defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a0f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(\n",
    "    model: torch.nn.Module,\n",
    "    data: Dict[str, np.ndarray],\n",
    "    n_epoch: int,\n",
    "    optimizer_params: Dict[str, float],\n",
    "    return_last_only: bool = True,\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    This function must return the train and test error.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model being used to classify.\n",
    "        data (Dict[str, np.ndarray]): A dictionary with keys [\"x\", \"y\", \"x_test\", \"y_test\"]\n",
    "        n_epoch (int): number of epochs to test\n",
    "        optimizer_params (Dict[str, float]): Dictionary with parameters for the optimizer, such as [\"lr\", \"momentum\"...].\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Return train and test error of the trained model.\n",
    "    \"\"\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e657966",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "Test your implementation and parameterization: Running it with MLP of size 100 should give you 0 train error. Make sure this is the case and that 0 train error is obtained not in the end of the traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf9c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c181867",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "\n",
    "Investigate double descent on the MLP class for no noise and noisy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6073f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c52dfef5",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Do the same for CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16d398cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN architecture\n",
    "\n",
    "def get_model_cnn(channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv1d(1, channels, 5, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(channels, channels, 3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv1d(channels, channels, 3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(channels * 5, 10),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473a7163",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "\n",
    "Write a short report about your findings and the impact of the different factors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
